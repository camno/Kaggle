{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c520eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#### INSTRUCTIONS FOR I/O (PLEASE READ) #######\n",
    "# Input data files are available in the read-only \"../input/\" (relative) or '/kaggle/input'(absolute) directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "input_path = '2024-flame-ai-challenge/dataset/'\n",
    "output_path = 'working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e979a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets test set input\n",
    "def getTestX(idx):\n",
    "    csv_file = test_df.reset_index().to_dict(orient='list')\n",
    "    dir_path = os.path.join(input_path, \"test\")\n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta, uin)\n",
    "    alpha = np.full_like(theta, alpha)\n",
    "\n",
    "    X = np.stack([theta, xi_f, uin, alpha], axis = -1) # (t, Nx, Ny, c) \n",
    "    X = torch.tensor(X)\n",
    "    return id, X\n",
    "\n",
    "#gets train set input\n",
    "def getTrainData(idx):\n",
    "    csv_file = train_df.reset_index().to_dict(orient = 'list')\n",
    "    dir_path = os.path.join(input_path, \"train\")\n",
    "    \n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    \n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype = \"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype = \"<f4\").reshape(nt, Nx, Ny)\n",
    "    \n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta, uin)\n",
    "    alpha = np.full_like(theta, alpha)\n",
    "    \n",
    "    X = np.stack([theta[:-19], xi_f[:-19], uin[:-19], alpha[:-19]], axis = -1) #(t, Nx, Ny, c), t range: 0->130\n",
    "    X = torch.tensor(X)\n",
    "    \n",
    "    Y = xi_f \n",
    "    Y = torch.tensor(Y)\n",
    "    return id, X, Y\n",
    "    \n",
    "#predicts with input\n",
    "def predict(idx, model):\n",
    "    id, X = getTestX(idx)\n",
    "    X = X.unsqueeze(0)\n",
    "    y_pred = model(X)\n",
    "    return id, y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= np.array(y_pred).flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds,orient='index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    #move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45558aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a torch model based on linear interpolation of fire spread\n",
    "# REPLACE THIS WITH YOUR MODEL LOADER TO MAKE YOUR PREDICTIONS\n",
    "\n",
    "class FireSpreadModel_LSSVM(nn.Module):\n",
    "    def __init__(self, input_size = 20, output_size = 9, n_predictions = 20):\n",
    "        super(FireSpreadModel_LSSVM, self).__init__()\n",
    "        # Linear layer: input_size -> output_size\n",
    "        # constants\n",
    "        self.n_predictions = n_predictions\n",
    "        # input size: previous 5 time steps of fire locations and thetas, plus slope and u\n",
    "        # (9 + 9) * 5 + 2 = 92\n",
    "        # output size: 9 \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        This model takes in:\n",
    "        Input: data, packed tensor at certain time step t-4 to t with dimension (5, nx, ny, 4)\n",
    "        \n",
    "        Outputs:\n",
    "        - fire_predictions: (n_predictions, nx, ny) \n",
    "        \"\"\"\n",
    "        # unpack the data\n",
    "        # thetas: 5 * nx * ny\n",
    "        # fires:  5 * nx * ny\n",
    "        # u10, slope: single\n",
    "        thetas, fires, u10, slope = self.unpack_data(data)\n",
    "        \n",
    "        # init the predicted fire location \n",
    "        fire_predictions = torch.zeros((self.n_predictions, fires.shape[1], fires.shape[2]))\n",
    "        \n",
    "        # init the current state of fire predictions\n",
    "        fire_predictions[0, :, :] = fires[-1, :, :]\n",
    "        \n",
    "        for t in range(1, self.n_predictions):\n",
    "            \n",
    "            # get the previous fire locations, assuming len(fire_loc) > 0\n",
    "            # using previous step to predict the next time step\n",
    "            fire_locations = self.get_fire_locations(fire_predictions[t - 1, :, :].squeeze())\n",
    "            for f in fire_locations:\n",
    "                \n",
    "                # get the fire_neighbors need to be updated\n",
    "                fire_neighbors = self.get_neighbors(f[0], f[1], fires.shape[1], fires.shape[2])\n",
    "                \n",
    "                # fire_history: fire status for the last 5 time steps in the fire_neighbors cells\n",
    "                # fire_history: 5 * nx * ny\n",
    "                if t < 5:\n",
    "                    fire_history = torch.zeros((fires.shape[0], fires.shape[1], fires.shape[2]))\n",
    "                    fire_history[:4 - t, :, :] = fires[t : 4, :, :]\n",
    "                    fire_history[4 - t : 5, :, :] = fire_predictions[:t + 1, :, :]\n",
    "                # \n",
    "                else:\n",
    "                    fire_history = fire_predictions[t - 4 : t + 1, :, :] # (5, nx, ny)\n",
    "                    \n",
    "                # prep the input data for the model \n",
    "                input_data = self.prep_input_data(thetas,\n",
    "                                                  fire_history, \n",
    "                                                  fire_neighbors, \n",
    "                                                  u10,\n",
    "                                                  slope)\n",
    "                # return \n",
    "                new_fire_status = self.fc(input_data)\n",
    "                \n",
    "                # update the predicted fire status in fire_predictions\n",
    "                self.update_fire_predictions(t, fire_predictions, fire_neighbors, new_fire_status)\n",
    "                \n",
    "        \n",
    "        return fire_predictions\n",
    "    \n",
    "    def update_fire_predictions(self, t, fire_predictions, fire_neighbors, new_fire_status):\n",
    "        \"\"\"update the fire_predictions \n",
    "        \"\"\"\n",
    "        for idx in range(len(fire_neighbors)):\n",
    "            i, j = fire_neighbors[idx]\n",
    "            if i == -1 and j == -1:\n",
    "                continue\n",
    "            fire_predictions[t, i, j] = max(fire_predictions[t, i, j], new_fire_status[idx])\n",
    "    \n",
    "    def prep_input_data(self, thetas, fires, fire_neighbors, u10, slope):\n",
    "        \"\"\" wrapping all the data required together to feed into the classifier, returning a tensor\n",
    "        theta: (nx * ny) tensor\n",
    "        fires: (5 * nx * ny) tensor\n",
    "        fire_locations: list of tuples\n",
    "        u10: single value \n",
    "        slope: single value\n",
    "        \"\"\"\n",
    "        # get the neighbor status \n",
    "            \n",
    "        f_status = self.neighbor_to_fire_status(fires, fire_neighbors)\n",
    "        t_status = self.neighbor_to_fire_status(thetas, fire_neighbors)\n",
    "        \n",
    "        # concat all the features, 9 * 5 + 9 * 5 + 1 + 1 = 92 feature in total \n",
    "        input_data = f_status + t_status + [u10.item()] + [slope.item()]\n",
    "        #\n",
    "        input_data = torch.tensor(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def unpack_data(self, data):\n",
    "        \"\"\" data:(5, nx, ny, 4) tensor containing the input data\n",
    "            index from 0 -> 3: theta, xi_f, uin, alpha\n",
    "        \"\"\"\n",
    "        # unpacking the data, u and slope are scalar values\n",
    "        thetas = data[:, :, :, 0].squeeze()       # thetas, 5 * nx * ny\n",
    "        fires  = data[:, :, :, 1].squeeze()       # fires, 5 * nx * ny\n",
    "        u10   = data[-1, :, :, 2].squeeze()        # u10, nx * ny\n",
    "        slope = data[-1, :, :, 3].squeeze()        # slope, nx * ny\n",
    "        \n",
    "        u10   = u10.mean()                    # u, only interested in the u as single value\n",
    "        slope = slope.mean()                  # slope, only interested in the slope as single value\n",
    "        return thetas, fires, u10, slope\n",
    "    \n",
    "    def neighbor_to_fire_status(self, fires, fire_neighbors):\n",
    "        \"\"\"get the fire status based on the neighbors\n",
    "        fires: 5 * nx * ny\n",
    "        \"\"\"\n",
    "        f_status = []\n",
    "        for t in range(fires.shape[0]):\n",
    "            for i, j in fire_neighbors:\n",
    "                if i == -1 and j == -1:\n",
    "                    f_status.append(-1)\n",
    "                else:\n",
    "                    f_status.append(fires[t, i, j].item())\n",
    "        return f_status\n",
    "    \n",
    "    def get_fire_locations(self, fires):\n",
    "        \"\"\"fires has the dimensions of nx * ny, same as the squeezed fire_predictions\n",
    "        return a list of tuples \n",
    "        \"\"\"\n",
    "        fire_locations = []\n",
    "        for i in range(fires.shape[0]):\n",
    "            for j in range(fires.shape[1]):\n",
    "                if fires[i][j] == 1:\n",
    "                    fire_locations.append((i, j))\n",
    "        return fire_locations\n",
    "                \n",
    "    def get_neighbors(self, x, y, M, N):\n",
    "        \"\"\"Returns the list of neighbor coordinates neighbors: \n",
    "        * * *     7 8 9\n",
    "        * o * ==> 4 5 6\n",
    "        * * *     1 2 3\n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "        for i in [-1, 0, 1]:\n",
    "            for j in [-1, 0, 1]:\n",
    "                new_x, new_y = x + i, y + j\n",
    "                if 0 <= new_x < M and 0 <= new_y < N:\n",
    "                    neighbors.append((new_x, new_y))\n",
    "                  # if at the boundary, insert -1\n",
    "                else:  \n",
    "                    neighbors.append((-1, -1))\n",
    "                    \n",
    "        return neighbors\n",
    "\n",
    "# LSSVM loss: least squares + regularization term\n",
    "def lssvm_loss_sf(y_pred, y_true, model, c = 1.0):\n",
    "    \"\"\"LSSVM Loss, Least-Squares Objective + Regularization\n",
    "        In this loss model, single final step is used to calc the loss function\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    LSSVM loss function: Least squares loss + regularization term\n",
    "    - y_pred: predicted output from the model, (20, nx, ny)\n",
    "    - y_true: true target labels, (20, nx, ny)\n",
    "    - model: the LSSVM model to apply regularization\n",
    "    - c: regularization constant\n",
    "    \"\"\"\n",
    " \n",
    "    # Least Squares loss (MSE)\n",
    "    least_squares_loss = 0.5 * torch.mean((y_pred[-1, :, :] - y_true[-1, :, :]) ** 2)\n",
    "    \n",
    "    # Regularization term: ||w||^2\n",
    "    regularization_loss = 0.5 * c * torch.sum(model.fc.weight ** 2)\n",
    "    \n",
    "    return least_squares_loss + regularization_loss\n",
    "\n",
    "# LSSVM loss: least squares + regularization term\n",
    "def lssvm_loss_full(y_pred, y_true, model, c = 1.0):\n",
    "    \"\"\"LSSVM Loss, Least-Squares Objective + Regularization\n",
    "        In this loss model, every single step is included in the loss calculation, not just final step\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    LSSVM loss function: Least squares loss + regularization term\n",
    "    - y_pred: predicted output from the model, (20, nx, ny)\n",
    "    - y_true: true target labels, (20, nx, ny)\n",
    "    - model: the LSSVM model to apply regularization\n",
    "    - c: regularization constant\n",
    "    \"\"\"\n",
    " \n",
    "    for t in range(1, y_pred.shape[0]):\n",
    "        # Least Squares loss (MSE)\n",
    "        least_squares_loss = 0.5 * torch.mean((y_pred[t, :, :] - y_true[t, :, :]) ** 2)\n",
    "    \n",
    "    # Regularization term: ||w||^2\n",
    "    regularization_loss = 0.5 * c * torch.sum(model.fc.weight ** 2)\n",
    "    \n",
    "    return least_squares_loss / (y_pred.shape[0] - 1) + regularization_loss\n",
    "\n",
    "\n",
    "def train_lssvm(model, X, Y, epochs = 10, lr = 0.001, c = 0.0):\n",
    "    \"\"\" X: (t, nx, ny, 4) tensor, t = 130, time step ranges from 0 - 131\n",
    "        Y: (t, nx, ny) tensor, t = 130, time step ranges from     1 - 150\n",
    "        at each time step t, using X to predict Y at time t + 19, \n",
    "        then calculate the loss function at t + 19 with Y at the same time \n",
    "        (based on the forward function in the sample.)\n",
    "        Hence, we need Y at t+ 1 to Y at t + 19 to train the model and validate the predictions. \n",
    "        \n",
    "        For each epoch, train through all the time steps, \n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # loop over all the time steps for 1 epoch\n",
    "        for t in range(X.shape[0] - 5):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass, input_data at time step t (5, nx, ny, 4)\n",
    "            input_data = X[t : t+5, :, :, :].squeeze()\n",
    "            # output a tensor from time t to t + 19   (20, nx, ny)\n",
    "            output_data = model(input_data)\n",
    "            \n",
    "            # Compute Loss\n",
    "            \n",
    "            # Option 1: only final time step is considered\n",
    "            loss = lssvm_loss_sf(output_data, Y[t : t + 20, :, :], model, c = c)\n",
    "            \n",
    "            # Option 2: \n",
    "#             loss = lssvm_loss_full(output_data, Y[t : t + 20, :, :], model, c = c)\n",
    "        \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "        #if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
    "        print(\"++ == ++ == \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0103ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"training a model for each training data set, then avg all the model paramters to get a new model \n",
    "\"\"\"\n",
    "def full_training(train_df, input_size, output_size, epochs = 5, lr = 0.001, c = 1.0):\n",
    "    \n",
    "    all_weights = []\n",
    "    all_bias = [] \n",
    "    for idx in range(len(train_df)):\n",
    "        \n",
    "        print(f\"idx = {idx}\")\n",
    "        \n",
    "        # get the training data set\n",
    "        id, X, Y = getTrainData(idx)\n",
    "        \n",
    "        # init a new model\n",
    "        model = FireSpreadModel_LSSVM(input_size, output_size) \n",
    "        \n",
    "        train_lssvm(model, X, Y, epochs = epochs, lr = lr, c = c)\n",
    "        \n",
    "        # Get the weights and bias\n",
    "        weights = model.fc.weight\n",
    "        bias = model.fc.bias\n",
    "        \n",
    "        # Convert weights and bias to numpy arrays\n",
    "        weights_numpy = weights.detach().numpy()\n",
    "        bias_numpy = bias.detach().numpy()\n",
    "        \n",
    "        # append all the weights and bias\n",
    "        all_weights.append(weights_numpy)\n",
    "        all_bias.append(bias_numpy)\n",
    "    \n",
    "    # average the all the weigts and bias and return the mean weights and bias\n",
    "    # Convert the list of arrays into a 3D NumPy array and compute the mean\n",
    "    mean_weights = np.mean(np.array(all_weights), axis = 0)\n",
    "    mean_bias = np.mean(np.array(all_bias), axis = 0)\n",
    "    \n",
    "    mean_weights = torch.tensor(mean_weights)\n",
    "    mean_bias = torch.tensor(mean_bias)\n",
    "    \n",
    "    \n",
    "    # init a new model and assign the mean weights and bias for the new model and  return \n",
    "    model = FireSpreadModel_LSSVM(input_size, output_size)        \n",
    "    # Assign custom weights and bias to the linear layer\n",
    "    with torch.no_grad():  # Use no_grad() to avoid tracking this assignment in the computation graph\n",
    "        model.fc.weight.copy_(mean_weights)\n",
    "        model.fc.bias.copy_(mean_bias)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "480c2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = 0\n",
      "Epoch 1/3, Loss: 0.012168142013251781\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.012168142013251781\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.012168142013251781\n",
      "++ == ++ == \n",
      "idx = 1\n",
      "Epoch 1/3, Loss: 0.011338495649397373\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.011338495649397373\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.011338495649397373\n",
      "++ == ++ == \n",
      "idx = 2\n",
      "Epoch 1/3, Loss: 0.012582964263856411\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.012582964263856411\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.012582964263856411\n",
      "++ == ++ == \n",
      "idx = 3\n",
      "Epoch 1/3, Loss: 0.017007743939757347\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.017007743939757347\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.017007743939757347\n",
      "++ == ++ == \n",
      "idx = 4\n",
      "Epoch 1/3, Loss: 0.0163163710385561\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.0163163710385561\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.0163163710385561\n",
      "++ == ++ == \n",
      "idx = 5\n",
      "Epoch 1/3, Loss: 0.012721238657832146\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.012721238657832146\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.012721238657832146\n",
      "++ == ++ == \n",
      "idx = 6\n",
      "Epoch 1/3, Loss: 0.012997787445783615\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.012997787445783615\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.012997787445783615\n",
      "++ == ++ == \n",
      "idx = 7\n",
      "Epoch 1/3, Loss: 0.013965708203613758\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.013965708203613758\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.013965708203613758\n",
      "++ == ++ == \n",
      "idx = 8\n",
      "Epoch 1/3, Loss: 0.01659291982650757\n",
      "++ == ++ == \n",
      "Epoch 2/3, Loss: 0.01659291982650757\n",
      "++ == ++ == \n",
      "Epoch 3/3, Loss: 0.01659291982650757\n",
      "++ == ++ == \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training section\n",
    "\"\"\"\n",
    "# read training dataframe\n",
    "train_df = pd.read_csv(os.path.join(input_path,'train.csv'))\n",
    "\n",
    "# the mdoel takes input features 92, output feature 9\n",
    "# input features include 9 * 5 fire status, 9 * 5 theta status, 1 wind speed, 1 slope \n",
    "# output features include 9 updated fire status\n",
    "input_size = 92\n",
    "output_size = 9\n",
    "\n",
    "model = full_training(train_df, input_size, output_size, epochs = 3, lr = 0.001, c = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e94d8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts with input\n",
    "def predict(idx, model):\n",
    "    # get test X\n",
    "    id, X = getTestX(idx)\n",
    "    # input data: final time step X\n",
    "    y_pred = model(X)\n",
    "    return id, y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model, test_df):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= y_pred.detach().numpy().flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds, orient = 'index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    # move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ff4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Submission file ... completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test section, generate submission files\n",
    "\"\"\"\n",
    "# read test data set \n",
    "test_df = pd.read_csv(os.path.join(input_path,'test.csv'))\n",
    "# generate submission data \n",
    "df = generate_submission(model, test_df)\n",
    "# save the submission data to file \n",
    "df.to_csv(os.path.join(output_path, 'draft-3_submission-SF.csv'),index = False)\n",
    "print('Generating Submission file ... completed' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2964f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44025ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8625a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b48a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08bc018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131, 113, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09efce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77732e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing training\n",
    "X: (t, nx, ny, 4) tensor, t = 130, time step ranges from 0 - 130\n",
    "Y: (t, nx, ny) tensor, t = 130, time step ranges from    0 - 149 \n",
    "at each time step t, using X to predict Y at time t + 19, (based on the forward function in the sample.)\n",
    "hence we need Y at t+ 1 to Y at t + 19 to train the model and validate the predictions \n",
    "\"\"\"\n",
    "# testing \n",
    "id, X, Y = getTrainData(1)\n",
    "\n",
    "# model takes in 'data' as the training / testing input \n",
    "# \n",
    "data = X\n",
    "target = Y\n",
    "\n",
    "# the mdoel takes input features 20, output feature 9\n",
    "# input features include 9 fire status, 9 theta status, 1 wind speed, 1 slope \n",
    "# output features include 9 updated fire status\n",
    "input_size = 20\n",
    "output_size = 9\n",
    "\n",
    "# Create LSSVM model\n",
    "model = FireSpreadModel_LSSVM(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_lssvm(model, X, Y, epochs = 3, lr = 0.005, c = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
