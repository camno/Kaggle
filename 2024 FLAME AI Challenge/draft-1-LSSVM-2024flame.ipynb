{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c520eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#### INSTRUCTIONS FOR I/O (PLEASE READ) #######\n",
    "# Input data files are available in the read-only \"../input/\" (relative) or '/kaggle/input'(absolute) directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "input_path = '2024-flame-ai-challenge/dataset/'\n",
    "output_path = 'working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a638e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(input_path,'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(input_path,'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e979a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets test set input\n",
    "def getTestX(idx):\n",
    "    csv_file = test_df.reset_index().to_dict(orient='list')\n",
    "    dir_path = os.path.join(input_path, \"test\")\n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta, uin)\n",
    "    alpha = np.full_like(theta, alpha)\n",
    "\n",
    "    X = np.stack([theta, xi_f, uin, alpha], axis = -1) # (t, Nx, Ny, c) \n",
    "    X = torch.tensor(X)\n",
    "    return id, X\n",
    "\n",
    "#gets train set input\n",
    "def getTrainData(idx):\n",
    "    csv_file = train_df.reset_index().to_dict(orient = 'list')\n",
    "    dir_path = os.path.join(input_path, \"train\")\n",
    "    \n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    \n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype = \"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype = \"<f4\").reshape(nt, Nx, Ny)\n",
    "    \n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta, uin)\n",
    "    alpha = np.full_like(theta, alpha)\n",
    "\n",
    "    X = np.stack([theta[:-19], xi_f[:-19], uin[:-19], alpha[:-19]], axis = -1) #(t, Nx, Ny, c), t range: 0->t-20\n",
    "    X = torch.tensor(X)\n",
    "    \n",
    "    Y = xi_f \n",
    "    Y = torch.tensor(Y)\n",
    "    return id, X, Y\n",
    "    \n",
    "#predicts with input\n",
    "def predict(idx, model):\n",
    "    id, X = getTestX(idx)\n",
    "    X = X.unsqueeze(0)\n",
    "    y_pred = model(X)\n",
    "    return id, y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= np.array(y_pred).flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds,orient='index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    #move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45558aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a torch model based on linear interpolation of fire spread\n",
    "# REPLACE THIS WITH YOUR MODEL LOADER TO MAKE YOUR PREDICTIONS\n",
    "\n",
    "class FireSpreadModel_LSSVM(nn.Module):\n",
    "    def __init__(self, input_size = 20, output_size = 9, n_predictions = 20):\n",
    "        super(FireSpreadModel_LSSVM, self).__init__()\n",
    "        # Linear layer: input_size -> output_size\n",
    "        # constants\n",
    "        self.n_predictions = n_predictions\n",
    "        # \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        This model takes in:\n",
    "        Input: data, packed tensor at certain time step t with dimension (nx, ny, 4)\n",
    "        \n",
    "        Outputs:\n",
    "        - fire_predictions: (n_predictions, nx, ny) \n",
    "        \"\"\"\n",
    "        # unpack the \n",
    "        thetas, fires, u10, slope = self.unpack_data(data)\n",
    "        \n",
    "        # init the predicted fire location \n",
    "        fire_predictions = torch.zeros((self.n_predictions, fires.shape[0], fires.shape[1]))\n",
    "        \n",
    "        # init the current state of fire predictions\n",
    "        fire_predictions[0, :, :] = fires\n",
    "        \n",
    "        for t in range(1, self.n_predictions):\n",
    "            \n",
    "            # get the previous fire locations, assuming len(fire_loc) > 0\n",
    "            # using previous step to predict the next time step\n",
    "#             if t == 1:\n",
    "#                 fire_locations = self.get_fire_locations(fires)\n",
    "#             else:\n",
    "#                 fire_locations = self.get_fire_locations(fire_predictions[t - 1, :, :].squeeze())\n",
    "            fire_locations = self.get_fire_locations(fire_predictions[t - 1, :, :].squeeze())\n",
    "            for f in fire_locations:\n",
    "                \n",
    "                # get the fire_neighbors need to be updated \n",
    "                fire_neighbors = self.get_neighbors(f[0], f[1], fires.shape[0], fires.shape[1])\n",
    "                \n",
    "                # prep the input data for the model \n",
    "                input_data = self.prep_input_data(thetas,\n",
    "                                                  fire_predictions[t - 1, :, :].squeeze(), \n",
    "                                                  fire_neighbors, \n",
    "                                                  u10,\n",
    "                                                  slope)\n",
    "                # return \n",
    "                new_fire_status = self.fc(input_data)\n",
    "                \n",
    "                # update the predicted fire status in fire_predictions\n",
    "                self.update_fire_predictions(t, fire_predictions, fire_neighbors, new_fire_status)\n",
    "                \n",
    "        \n",
    "        return fire_predictions\n",
    "    \n",
    "    def update_fire_predictions(self, t, fire_predictions, fire_neighbors, new_fire_status):\n",
    "        \"\"\"update the fire_predictions \n",
    "        \"\"\"\n",
    "        for idx in range(len(fire_neighbors)):\n",
    "            i, j = fire_neighbors[idx]\n",
    "            if i == -1 and j == -1:\n",
    "                continue\n",
    "            fire_predictions[t, i, j] = max(fire_predictions[t, i, j], new_fire_status[idx])\n",
    "    \n",
    "    def prep_input_data(self, thetas, fires, fire_neighbors, u10, slope):\n",
    "        \"\"\" wrapping all the data required together to feed into the classifier, returning a tensor\n",
    "        theta: (nx * ny) tensor\n",
    "        fires: (nx * ny) tensor\n",
    "        fire_locations: list of tuples\n",
    "        u10: single value \n",
    "        slope: single value\n",
    "        \"\"\"\n",
    "        # get the neighbor status \n",
    "            \n",
    "        f_status = self.neighbor_to_fire_status(fires, fire_neighbors)\n",
    "        t_status = self.neighbor_to_fire_status(thetas, fire_neighbors)\n",
    "        \n",
    "        # concat all the features, 9 + 9 + 1 + 1 = 20 feature in total \n",
    "        input_data = f_status + t_status + [u10.item()] + [slope.item()]\n",
    "        #\n",
    "        input_data = torch.tensor(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def unpack_data(self, data):\n",
    "        \"\"\" data:(nx, ny, 4) tensor containing the input data\n",
    "            index from 0 -> 3: theta, xi_f, uin, alpha\n",
    "        \"\"\"\n",
    "        # unpacking the data, u and slope are scalar values\n",
    "        thetas = data[:, :, 0].squeeze()       # thetas, nx * ny\n",
    "        fires  = data[:, :, 1].squeeze()       # fires, nx * ny\n",
    "        u10   = data[:, :, 2].squeeze()        # u10, nx * ny\n",
    "        slope = data[:, :, 3].squeeze()        # slope, nx * ny\n",
    "        \n",
    "        u10   = u10.mean()                    # u, only interested in the u as single value\n",
    "        slope = slope.mean()                  # slope, only interested in the slope as single value\n",
    "        return thetas, fires, u10, slope\n",
    "    \n",
    "    def neighbor_to_fire_status(self, fires, fire_neighbors):\n",
    "        \"\"\"get the fire status based on the \n",
    "        \"\"\"\n",
    "        f_status = []\n",
    "        for i, j in fire_neighbors:\n",
    "            if i == -1 and j == -1:\n",
    "                f_status.append(-1)\n",
    "            else:\n",
    "                f_status.append(fires[i, j].item())\n",
    "        return f_status\n",
    "    \n",
    "    def get_fire_locations(self, fires):\n",
    "        \"\"\"fires has the dimensions of nx * ny, same as the squeezed fire_predictions\n",
    "        return a list of tuples \n",
    "        \"\"\"\n",
    "        fire_locations = []\n",
    "        for i in range(fires.shape[0]):\n",
    "            for j in range(fires.shape[1]):\n",
    "                if fires[i][j] == 1:\n",
    "                    fire_locations.append((i, j))\n",
    "        return fire_locations\n",
    "                \n",
    "    def get_neighbors(self, x, y, M, N):\n",
    "        \"\"\"Returns the list of neighbor coordinates neighbors: \n",
    "        * * *     7 8 9\n",
    "        * o * ==> 4 5 6\n",
    "        * * *     1 2 3\n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "        for i in [-1, 0, 1]:\n",
    "            for j in [-1, 0, 1]:\n",
    "                new_x, new_y = x + i, y + j\n",
    "                if 0 <= new_x < M and 0 <= new_y < N:\n",
    "                    neighbors.append((new_x, new_y))\n",
    "                  # if at the boundary, insert -1\n",
    "                else:  \n",
    "                    neighbors.append((-1, -1))\n",
    "                    \n",
    "        return neighbors\n",
    "\n",
    "# LSSVM loss: least squares + regularization term\n",
    "def lssvm_loss_SF(y_pred, y_true, model, c = 1.0):\n",
    "    \"\"\"LSSVM Loss, Least-Squares Objective + Regularization\n",
    "        In this loss model, single final step is used to calc the loss function\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    LSSVM loss function: Least squares loss + regularization term\n",
    "    - y_pred: predicted output from the model, (20, nx, ny)\n",
    "    - y_true: true target labels, (20, nx, ny)\n",
    "    - model: the LSSVM model to apply regularization\n",
    "    - c: regularization constant\n",
    "    \"\"\"\n",
    " \n",
    "    # Least Squares loss (MSE)\n",
    "    least_squares_loss = 0.5 * torch.mean((y_pred[-1, :, :] - y_true[-1, :, :]) ** 2)\n",
    "    \n",
    "    # Regularization term: ||w||^2\n",
    "    regularization_loss = 0.5 * c * torch.sum(model.fc.weight ** 2)\n",
    "    \n",
    "    return least_squares_loss + regularization_loss\n",
    "\n",
    "# LSSVM loss: least squares + regularization term\n",
    "def lssvm_loss_full(y_pred, y_true, model, c = 1.0):\n",
    "    \"\"\"LSSVM Loss, Least-Squares Objective + Regularization\n",
    "        In this loss model, every single step is included in the loss calculation, not just final step\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    LSSVM loss function: Least squares loss + regularization term\n",
    "    - y_pred: predicted output from the model, (20, nx, ny)\n",
    "    - y_true: true target labels, (20, nx, ny)\n",
    "    - model: the LSSVM model to apply regularization\n",
    "    - c: regularization constant\n",
    "    \"\"\"\n",
    " \n",
    "    for t in range(1, y_pred.shape[0]):\n",
    "        # Least Squares loss (MSE)\n",
    "        least_squares_loss = 0.5 * torch.mean((y_pred[t, :, :] - y_true[t, :, :]) ** 2)\n",
    "    \n",
    "    # Regularization term: ||w||^2\n",
    "    regularization_loss = 0.5 * c * torch.sum(model.fc.weight ** 2)\n",
    "    \n",
    "    return least_squares_loss / (y_pred.shape[0] - 1) + regularization_loss\n",
    "\n",
    "\n",
    "def train_lssvm(model, X, Y, epochs = 10, lr = 0.01, c = 1.0):\n",
    "    \"\"\" X: (t, nx, ny, 4) tensor, t = 130, time step ranges from 0 - 131\n",
    "        Y: (t, nx, ny) tensor, t = 130, time step ranges from     1 - 150\n",
    "        at each time step t, using X to predict Y at time t + 19, \n",
    "        then calculate the loss function at t + 19 with Y at the same time \n",
    "        (based on the forward function in the sample.)\n",
    "        Hence, we need Y at t+ 1 to Y at t + 19 to train the model and validate the predictions. \n",
    "        \n",
    "        For each epoch, train through all the time steps, \n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # loop over all the time steps for 1 epoch\n",
    "        for t in range(X.shape[0]):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass, input_data at time step t (nx, ny, 4)\n",
    "            input_data = X[t, :, :, :].squeeze()\n",
    "            # output a tensor from time t to t + 19   (20, nx, ny)\n",
    "            output_data = model(input_data)\n",
    "            \n",
    "            # Compute Loss\n",
    "            \n",
    "            # Option 1: only final time step is considered\n",
    "            # loss = lssvm_loss(output_data, Y[t : t + 20, :, :], model, c = c)\n",
    "            \n",
    "            # Option 2: \n",
    "            loss = lssvm_loss_full(output_data, Y[t : t + 20, :, :], model, c = c)\n",
    "        \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            if t % 70 == 0:\n",
    "                print(f'T {t}/{X.shape[0]}, Loss: {loss.item()}')\n",
    "        \n",
    "        #if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{epochs}, Loss: {loss.item()}')\n",
    "        print(\"++ == ++ == \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0103ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Full training based on all the training data \n",
    "\"\"\"\n",
    "def full_training(model, train_df, epochs = 2, c = 1):\n",
    "    \n",
    "    lrs = [0.001]\n",
    "    for lr in lrs:\n",
    "        for idx in range(len(train_df)):\n",
    "            print(f\"idx = {idx}\")\n",
    "            id, X, Y = getTrainData(idx)\n",
    "            train_lssvm(model, X, Y, epochs = 2, lr = lr, c = c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d06eab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = 0\n",
      "T 0/131, Loss: 1.5402206182479858\n",
      "T 70/131, Loss: 0.9506608247756958\n",
      "Epoch 0/2, Loss: 0.6170690655708313\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.6123374104499817\n",
      "T 70/131, Loss: 0.36100420355796814\n",
      "Epoch 1/2, Loss: 0.22397153079509735\n",
      "++ == ++ == \n",
      "idx = 1\n",
      "T 0/131, Loss: 0.22188982367515564\n",
      "T 70/131, Loss: 0.0777876004576683\n",
      "Epoch 0/2, Loss: 0.02961094118654728\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.028793761506676674\n",
      "T 70/131, Loss: 0.008640266954898834\n",
      "Epoch 1/2, Loss: 0.0031539052724838257\n",
      "++ == ++ == \n",
      "idx = 2\n",
      "T 0/131, Loss: 0.0028564108069986105\n",
      "T 70/131, Loss: 0.000940444937441498\n",
      "Epoch 0/2, Loss: 0.0008369262795895338\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.00048032376798801124\n",
      "T 70/131, Loss: 0.0009388100006617606\n",
      "Epoch 1/2, Loss: 0.0008369236020371318\n",
      "++ == ++ == \n",
      "idx = 3\n",
      "T 0/131, Loss: 0.00043665579869411886\n",
      "T 70/131, Loss: 0.0006258773501031101\n",
      "Epoch 0/2, Loss: 0.0009169771801680326\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.00043665579869411886\n",
      "T 70/131, Loss: 0.000625873333774507\n",
      "Epoch 1/2, Loss: 0.0009169771801680326\n",
      "++ == ++ == \n",
      "idx = 4\n",
      "T 0/131, Loss: 0.00033476942917332053\n",
      "T 70/131, Loss: 0.001033423701301217\n",
      "Epoch 0/2, Loss: 0.0008223684271797538\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.00033476942917332053\n",
      "T 70/131, Loss: 0.0010334188118577003\n",
      "Epoch 1/2, Loss: 0.0008223684271797538\n",
      "++ == ++ == \n",
      "idx = 5\n",
      "T 0/131, Loss: 0.0004075454198755324\n",
      "T 70/131, Loss: 0.0010479785269126296\n",
      "Epoch 0/2, Loss: 0.0007350372616201639\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.0004075454198755324\n",
      "T 70/131, Loss: 0.0010479739867150784\n",
      "Epoch 1/2, Loss: 0.0007350372616201639\n",
      "++ == ++ == \n",
      "idx = 6\n",
      "T 0/131, Loss: 0.0005021541728638113\n",
      "T 70/131, Loss: 0.0006840989808551967\n",
      "Epoch 0/2, Loss: 0.0005749301053583622\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.0005021541728638113\n",
      "T 70/131, Loss: 0.00068409409141168\n",
      "Epoch 1/2, Loss: 0.0005749301053583622\n",
      "++ == ++ == \n",
      "idx = 7\n",
      "T 0/131, Loss: 0.0004584885900840163\n",
      "T 70/131, Loss: 0.00063315563602373\n",
      "Epoch 0/2, Loss: 0.0006622612709179521\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.0004584885900840163\n",
      "T 70/131, Loss: 0.000633150921203196\n",
      "Epoch 1/2, Loss: 0.0006622612709179521\n",
      "++ == ++ == \n",
      "idx = 8\n",
      "T 0/131, Loss: 0.0005167094059288502\n",
      "T 70/131, Loss: 0.0008150957291945815\n",
      "Epoch 0/2, Loss: 0.0009970307582989335\n",
      "++ == ++ == \n",
      "T 0/131, Loss: 0.0005167094059288502\n",
      "T 70/131, Loss: 0.0008150908397510648\n",
      "Epoch 1/2, Loss: 0.0009970307582989335\n",
      "++ == ++ == \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training section\n",
    "\"\"\"\n",
    "# read training dataframe\n",
    "train_df = pd.read_csv(os.path.join(input_path,'train.csv'))\n",
    "\n",
    "# the mdoel takes input features 20, output feature 9\n",
    "# input features include 9 fire status, 9 theta status, 1 wind speed, 1 slope \n",
    "# output features include 9 updated fire status\n",
    "input_size = 20\n",
    "output_size = 9\n",
    "# Create LSSVM model\n",
    "model = FireSpreadModel_LSSVM(input_size, output_size)\n",
    "\n",
    "full_training(model, train_df, epochs = 2, c = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b869f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9906e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts with input\n",
    "def predict(idx, model):\n",
    "    # get test X\n",
    "    id, X = getTestX(idx)\n",
    "    # input data: final time step X\n",
    "    y_pred = model(X[-1, :, :, :].squeeze())\n",
    "    return id, y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model, test_df):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= y_pred.detach().numpy().flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds, orient = 'index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    # move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28a6a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Submission file ... completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test section, generate submission files\n",
    "\"\"\"\n",
    "test_df = pd.read_csv(os.path.join(input_path,'test.csv'))\n",
    "df = generate_submission(model, test_df)\n",
    "df.to_csv(os.path.join(output_path, 'submission.csv'),index=False)\n",
    "print('Generating Submission file ... completed' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493df4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59998822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output model parameters\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8625a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b48a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08bc018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131, 113, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09efce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing training\n",
    "X: (t, nx, ny, 4) tensor, t = 130, time step ranges from 0 - 130\n",
    "Y: (t, nx, ny) tensor, t = 130, time step ranges from    0 - 149 \n",
    "at each time step t, using X to predict Y at time t + 19, (based on the forward function in the sample.)\n",
    "hence we need Y at t+ 1 to Y at t + 19 to train the model and validate the predictions \n",
    "\"\"\"\n",
    "# testing \n",
    "id, X, Y = getTrainData(1)\n",
    "\n",
    "# model takes in 'data' as the training / testing input \n",
    "# \n",
    "data = X\n",
    "target = Y\n",
    "\n",
    "# the mdoel takes input features 20, output feature 9\n",
    "# input features include 9 fire status, 9 theta status, 1 wind speed, 1 slope \n",
    "# output features include 9 updated fire status\n",
    "input_size = 20\n",
    "output_size = 9\n",
    "\n",
    "# Create LSSVM model\n",
    "model = FireSpreadModel_LSSVM(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_lssvm(model, X, Y, epochs = 3, lr = 0.005, c = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
