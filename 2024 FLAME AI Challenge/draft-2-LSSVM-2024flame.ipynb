{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74c520eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#### INSTRUCTIONS FOR I/O (PLEASE READ) #######\n",
    "# Input data files are available in the read-only \"../input/\" (relative) or '/kaggle/input'(absolute) directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "input_path = '2024-flame-ai-challenge/dataset/'\n",
    "output_path = 'working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e979a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets test set input\n",
    "def getTestX(idx):\n",
    "    csv_file = test_df.reset_index().to_dict(orient='list')\n",
    "    dir_path = os.path.join(input_path, \"test\")\n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta, uin)\n",
    "    alpha = np.full_like(theta, alpha)\n",
    "\n",
    "    X = np.stack([theta, xi_f, uin, alpha], axis = -1) # (t, Nx, Ny, c) \n",
    "    X = torch.tensor(X)\n",
    "    return id, X\n",
    "\n",
    "#gets train set input\n",
    "def getTrainData(idx):\n",
    "    csv_file = train_df.reset_index().to_dict(orient = 'list')\n",
    "    dir_path = os.path.join(input_path, \"train\")\n",
    "    \n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    \n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype = \"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype = \"<f4\").reshape(nt, Nx, Ny)\n",
    "    \n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta, uin)\n",
    "    alpha = np.full_like(theta, alpha)\n",
    "\n",
    "    X = np.stack([theta[:-19], xi_f[:-19], uin[:-19], alpha[:-19]], axis = -1) #(t, Nx, Ny, c), t range: 0->130\n",
    "    X = torch.tensor(X)\n",
    "    \n",
    "    Y = xi_f \n",
    "    Y = torch.tensor(Y)\n",
    "    return id, X, Y\n",
    "    \n",
    "#predicts with input\n",
    "def predict(idx, model):\n",
    "    id, X = getTestX(idx)\n",
    "    X = X.unsqueeze(0)\n",
    "    y_pred = model(X)\n",
    "    return id, y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= np.array(y_pred).flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds,orient='index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    #move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45558aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a torch model based on linear interpolation of fire spread\n",
    "# REPLACE THIS WITH YOUR MODEL LOADER TO MAKE YOUR PREDICTIONS\n",
    "\n",
    "class FireSpreadModel_LSSVM(nn.Module):\n",
    "    def __init__(self, input_size = 20, output_size = 9, n_predictions = 20):\n",
    "        super(FireSpreadModel_LSSVM, self).__init__()\n",
    "        # Linear layer: input_size -> output_size\n",
    "        # constants\n",
    "        self.n_predictions = n_predictions\n",
    "        # \n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        This model takes in:\n",
    "        Input: data, packed tensor at certain time step t with dimension (nx, ny, 4)\n",
    "        \n",
    "        Outputs:\n",
    "        - fire_predictions: (n_predictions, nx, ny) \n",
    "        \"\"\"\n",
    "        # unpack the \n",
    "        thetas, fires, u10, slope = self.unpack_data(data)\n",
    "        \n",
    "        # init the predicted fire location \n",
    "        fire_predictions = torch.zeros((self.n_predictions, fires.shape[0], fires.shape[1]))\n",
    "        \n",
    "        # init the current state of fire predictions\n",
    "        fire_predictions[0, :, :] = fires\n",
    "        \n",
    "        for t in range(1, self.n_predictions):\n",
    "            \n",
    "            # get the previous fire locations, assuming len(fire_loc) > 0\n",
    "            # using previous step to predict the next time step\n",
    "#             if t == 1:\n",
    "#                 fire_locations = self.get_fire_locations(fires)\n",
    "#             else:\n",
    "#                 fire_locations = self.get_fire_locations(fire_predictions[t - 1, :, :].squeeze())\n",
    "            fire_locations = self.get_fire_locations(fire_predictions[t - 1, :, :].squeeze())\n",
    "            for f in fire_locations:\n",
    "                \n",
    "                # get the fire_neighbors need to be updated \n",
    "                fire_neighbors = self.get_neighbors(f[0], f[1], fires.shape[0], fires.shape[1])\n",
    "                \n",
    "                # prep the input data for the model \n",
    "                input_data = self.prep_input_data(thetas,\n",
    "                                                  fire_predictions[t - 1, :, :].squeeze(), \n",
    "                                                  fire_neighbors, \n",
    "                                                  u10,\n",
    "                                                  slope)\n",
    "                # return \n",
    "                new_fire_status = self.fc(input_data)\n",
    "                \n",
    "                # update the predicted fire status in fire_predictions\n",
    "                self.update_fire_predictions(t, fire_predictions, fire_neighbors, new_fire_status)\n",
    "                \n",
    "        \n",
    "        return fire_predictions\n",
    "    \n",
    "    def update_fire_predictions(self, t, fire_predictions, fire_neighbors, new_fire_status):\n",
    "        \"\"\"update the fire_predictions \n",
    "        \"\"\"\n",
    "        for idx in range(len(fire_neighbors)):\n",
    "            i, j = fire_neighbors[idx]\n",
    "            if i == -1 and j == -1:\n",
    "                continue\n",
    "            fire_predictions[t, i, j] = max(fire_predictions[t, i, j], new_fire_status[idx])\n",
    "    \n",
    "    def prep_input_data(self, thetas, fires, fire_neighbors, u10, slope):\n",
    "        \"\"\" wrapping all the data required together to feed into the classifier, returning a tensor\n",
    "        theta: (nx * ny) tensor\n",
    "        fires: (nx * ny) tensor\n",
    "        fire_locations: list of tuples\n",
    "        u10: single value \n",
    "        slope: single value\n",
    "        \"\"\"\n",
    "        # get the neighbor status \n",
    "            \n",
    "        f_status = self.neighbor_to_fire_status(fires, fire_neighbors)\n",
    "        t_status = self.neighbor_to_fire_status(thetas, fire_neighbors)\n",
    "        \n",
    "        # concat all the features, 9 + 9 + 1 + 1 = 20 feature in total \n",
    "        input_data = f_status + t_status + [u10.item()] + [slope.item()]\n",
    "        #\n",
    "        input_data = torch.tensor(input_data)\n",
    "        return input_data\n",
    "    \n",
    "    def unpack_data(self, data):\n",
    "        \"\"\" data:(nx, ny, 4) tensor containing the input data\n",
    "            index from 0 -> 3: theta, xi_f, uin, alpha\n",
    "        \"\"\"\n",
    "        # unpacking the data, u and slope are scalar values\n",
    "        thetas = data[:, :, 0].squeeze()       # thetas, nx * ny\n",
    "        fires  = data[:, :, 1].squeeze()       # fires, nx * ny\n",
    "        u10   = data[:, :, 2].squeeze()        # u10, nx * ny\n",
    "        slope = data[:, :, 3].squeeze()        # slope, nx * ny\n",
    "        \n",
    "        u10   = u10.mean()                    # u, only interested in the u as single value\n",
    "        slope = slope.mean()                  # slope, only interested in the slope as single value\n",
    "        return thetas, fires, u10, slope\n",
    "    \n",
    "    def neighbor_to_fire_status(self, fires, fire_neighbors):\n",
    "        \"\"\"get the fire status based on the \n",
    "        \"\"\"\n",
    "        f_status = []\n",
    "        for i, j in fire_neighbors:\n",
    "            if i == -1 and j == -1:\n",
    "                f_status.append(-1)\n",
    "            else:\n",
    "                f_status.append(fires[i, j].item())\n",
    "        return f_status\n",
    "    \n",
    "    def get_fire_locations(self, fires):\n",
    "        \"\"\"fires has the dimensions of nx * ny, same as the squeezed fire_predictions\n",
    "        return a list of tuples \n",
    "        \"\"\"\n",
    "        fire_locations = []\n",
    "        for i in range(fires.shape[0]):\n",
    "            for j in range(fires.shape[1]):\n",
    "                if fires[i][j] == 1:\n",
    "                    fire_locations.append((i, j))\n",
    "        return fire_locations\n",
    "                \n",
    "    def get_neighbors(self, x, y, M, N):\n",
    "        \"\"\"Returns the list of neighbor coordinates neighbors: \n",
    "        * * *     7 8 9\n",
    "        * o * ==> 4 5 6\n",
    "        * * *     1 2 3\n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "        for i in [-1, 0, 1]:\n",
    "            for j in [-1, 0, 1]:\n",
    "                new_x, new_y = x + i, y + j\n",
    "                if 0 <= new_x < M and 0 <= new_y < N:\n",
    "                    neighbors.append((new_x, new_y))\n",
    "                  # if at the boundary, insert -1\n",
    "                else:  \n",
    "                    neighbors.append((-1, -1))\n",
    "                    \n",
    "        return neighbors\n",
    "\n",
    "# LSSVM loss: least squares + regularization term\n",
    "def lssvm_loss_SF(y_pred, y_true, model, c = 1.0):\n",
    "    \"\"\"LSSVM Loss, Least-Squares Objective + Regularization\n",
    "        In this loss model, single final step is used to calc the loss function\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    LSSVM loss function: Least squares loss + regularization term\n",
    "    - y_pred: predicted output from the model, (20, nx, ny)\n",
    "    - y_true: true target labels, (20, nx, ny)\n",
    "    - model: the LSSVM model to apply regularization\n",
    "    - c: regularization constant\n",
    "    \"\"\"\n",
    " \n",
    "    # Least Squares loss (MSE)\n",
    "    least_squares_loss = 0.5 * torch.mean((y_pred[-1, :, :] - y_true[-1, :, :]) ** 2)\n",
    "    \n",
    "    # Regularization term: ||w||^2\n",
    "    regularization_loss = 0.5 * c * torch.sum(model.fc.weight ** 2)\n",
    "    \n",
    "    return least_squares_loss + regularization_loss\n",
    "\n",
    "# LSSVM loss: least squares + regularization term\n",
    "def lssvm_loss_full(y_pred, y_true, model, c = 1.0):\n",
    "    \"\"\"LSSVM Loss, Least-Squares Objective + Regularization\n",
    "        In this loss model, every single step is included in the loss calculation, not just final step\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    LSSVM loss function: Least squares loss + regularization term\n",
    "    - y_pred: predicted output from the model, (20, nx, ny)\n",
    "    - y_true: true target labels, (20, nx, ny)\n",
    "    - model: the LSSVM model to apply regularization\n",
    "    - c: regularization constant\n",
    "    \"\"\"\n",
    " \n",
    "    for t in range(1, y_pred.shape[0]):\n",
    "        # Least Squares loss (MSE)\n",
    "        least_squares_loss = 0.5 * torch.mean((y_pred[t, :, :] - y_true[t, :, :]) ** 2)\n",
    "    \n",
    "    # Regularization term: ||w||^2\n",
    "    regularization_loss = 0.5 * c * torch.sum(model.fc.weight ** 2)\n",
    "    \n",
    "    return least_squares_loss / (y_pred.shape[0] - 1) + regularization_loss\n",
    "\n",
    "\n",
    "def train_lssvm(model, X, Y, epochs = 10, lr = 0.01, c = 1.0):\n",
    "    \"\"\" X: (t, nx, ny, 4) tensor, t = 130, time step ranges from 0 - 131\n",
    "        Y: (t, nx, ny) tensor, t = 130, time step ranges from     1 - 150\n",
    "        at each time step t, using X to predict Y at time t + 19, \n",
    "        then calculate the loss function at t + 19 with Y at the same time \n",
    "        (based on the forward function in the sample.)\n",
    "        Hence, we need Y at t+ 1 to Y at t + 19 to train the model and validate the predictions. \n",
    "        \n",
    "        For each epoch, train through all the time steps, \n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # loop over all the time steps for 1 epoch\n",
    "        for t in range(X.shape[0]):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass, input_data at time step t (nx, ny, 4)\n",
    "            input_data = X[t, :, :, :].squeeze()\n",
    "            # output a tensor from time t to t + 19   (20, nx, ny)\n",
    "            output_data = model(input_data)\n",
    "            \n",
    "            # Compute Loss\n",
    "            \n",
    "            # Option 1: only final time step is considered\n",
    "            # loss = lssvm_loss(output_data, Y[t : t + 20, :, :], model, c = c)\n",
    "            \n",
    "            # Option 2: \n",
    "            loss = lssvm_loss_full(output_data, Y[t : t + 20, :, :], model, c = c)\n",
    "        \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "        #if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
    "        print(\"++ == ++ == \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0103ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"training a model for each training data set, then avg all the model paramters to get a new model \n",
    "\"\"\"\n",
    "def full_training(train_df, input_size, output_size, epochs = 5, lr = 0.001, c = 1.0):\n",
    "    \n",
    "    all_weights = []\n",
    "    all_bias = [] \n",
    "    for idx in range(len(train_df)):\n",
    "        \n",
    "        print(f\"idx = {idx}\")\n",
    "        \n",
    "        # get the training data set\n",
    "        id, X, Y = getTrainData(idx)\n",
    "        \n",
    "        # init a new model\n",
    "        model = FireSpreadModel_LSSVM(input_size, output_size) \n",
    "        \n",
    "        train_lssvm(model, X, Y, epochs = epochs, lr = lr, c = c)\n",
    "        \n",
    "        # Get the weights and bias\n",
    "        weights = model.fc.weight\n",
    "        bias = model.fc.bias\n",
    "        \n",
    "        # Convert weights and bias to numpy arrays\n",
    "        weights_numpy = weights.detach().numpy()\n",
    "        bias_numpy = bias.detach().numpy()\n",
    "        \n",
    "        # append all the weights and bias\n",
    "        all_weights.append(weights_numpy)\n",
    "        all_bias.append(bias_numpy)\n",
    "    \n",
    "    # average the all the weigts and bias and return the mean weights and bias\n",
    "    # Convert the list of arrays into a 3D NumPy array and compute the mean\n",
    "    mean_weights = np.mean(np.array(all_weights), axis = 0)\n",
    "    mean_bias = np.mean(np.array(all_bias), axis = 0)\n",
    "    \n",
    "    mean_weights = torch.tensor(mean_weights)\n",
    "    mean_bias = torch.tensor(mean_bias)\n",
    "    \n",
    "    \n",
    "    # init a new model and assign the mean weights and bias for the new model and  return \n",
    "    model = FireSpreadModel_LSSVM(input_size, output_size)        \n",
    "    # Assign custom weights and bias to the linear layer\n",
    "    with torch.no_grad():  # Use no_grad() to avoid tracking this assignment in the computation graph\n",
    "        model.fc.weight.copy_(mean_weights)\n",
    "        model.fc.bias.copy_(mean_bias)\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "480c2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = 0\n",
      "Epoch 1/6, Loss: 0.2060161828994751\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.01793697662651539\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0015202299691736698\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0006857803091406822\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.0006626013200730085\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0006622637156397104\n",
      "++ == ++ == \n",
      "idx = 1\n",
      "Epoch 1/6, Loss: 0.18531067669391632\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.015252585522830486\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0013969037681818008\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.000744796241633594\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.000727990991435945\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0007277613040059805\n",
      "++ == ++ == \n",
      "idx = 2\n",
      "Epoch 1/6, Loss: 0.20594322681427002\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.017389381304383278\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0015778596280142665\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0008545793825760484\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.0008371404837816954\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0008369249408133328\n",
      "++ == ++ == \n",
      "idx = 3\n",
      "Epoch 1/6, Loss: 0.18045078217983246\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.016834469512104988\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0017290309770032763\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0009397094254381955\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.000917313271202147\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0009169796830974519\n",
      "++ == ++ == \n",
      "idx = 4\n",
      "Epoch 1/6, Loss: 0.19277240335941315\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.017731409519910812\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.001693724887445569\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0008467501611448824\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.0008227241924032569\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.000822370988316834\n",
      "++ == ++ == \n",
      "idx = 5\n",
      "Epoch 1/6, Loss: 0.2056383341550827\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.017660362645983696\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0015252495650202036\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0007553601171821356\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.0007353166583925486\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0007350391824729741\n",
      "++ == ++ == \n",
      "idx = 6\n",
      "Epoch 1/6, Loss: 0.19864599406719208\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.01694379560649395\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0013631347101181746\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0005961495917290449\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.0005752337747253478\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.000574932259041816\n",
      "++ == ++ == \n",
      "idx = 7\n",
      "Epoch 1/6, Loss: 0.236746147274971\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.021880537271499634\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0017185824690386653\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.0006905890186317265\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.0006626591202802956\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0006622640648856759\n",
      "++ == ++ == \n",
      "idx = 8\n",
      "Epoch 1/6, Loss: 0.18581975996494293\n",
      "++ == ++ == \n",
      "Epoch 2/6, Loss: 0.016402937471866608\n",
      "++ == ++ == \n",
      "Epoch 3/6, Loss: 0.0017059377860277891\n",
      "++ == ++ == \n",
      "Epoch 4/6, Loss: 0.001014412846416235\n",
      "++ == ++ == \n",
      "Epoch 5/6, Loss: 0.000997257069684565\n",
      "++ == ++ == \n",
      "Epoch 6/6, Loss: 0.0009970322716981173\n",
      "++ == ++ == \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training section\n",
    "\"\"\"\n",
    "# read training dataframe\n",
    "train_df = pd.read_csv(os.path.join(input_path,'train.csv'))\n",
    "\n",
    "# the mdoel takes input features 20, output feature 9\n",
    "# input features include 9 fire status, 9 theta status, 1 wind speed, 1 slope \n",
    "# output features include 9 updated fire status\n",
    "input_size = 20\n",
    "output_size = 9\n",
    "\n",
    "model = full_training(train_df, input_size, output_size, epochs = 6, lr = 0.001, c = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e94d8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts with input\n",
    "def predict(idx, model):\n",
    "    # get test X\n",
    "    id, X = getTestX(idx)\n",
    "    # input data: final time step X\n",
    "    y_pred = model(X[-1, :, :, :].squeeze())\n",
    "    return id, y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model, test_df):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= y_pred.detach().numpy().flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds, orient = 'index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    # move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4ff4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Submission file ... completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test section, generate submission files\n",
    "\"\"\"\n",
    "# read test data set \n",
    "test_df = pd.read_csv(os.path.join(input_path,'test.csv'))\n",
    "# generate submission data \n",
    "df = generate_submission(model, test_df)\n",
    "# save the submission data to file \n",
    "df.to_csv(os.path.join(output_path, 'draft2-submission.csv'),index = False)\n",
    "print('Generating Submission file ... completed' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2964f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a44025ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 2.2597e-06, -4.5230e-08,  3.2935e-05, -1.5462e-05,  1.3997e-06,\n",
      "          6.7101e-06, -4.4712e-07, -1.5464e-07, -1.0102e-05, -1.2100e-06,\n",
      "          1.6716e-05, -1.0141e-06, -3.1988e-05,  1.8544e-08, -1.9164e-06,\n",
      "         -1.3739e-06, -1.6020e-05,  8.4099e-07, -1.0185e-12, -3.0420e-06],\n",
      "        [-2.3115e-07,  1.1111e-12, -2.2700e-05, -3.1431e-05,  3.2720e-06,\n",
      "         -5.2982e-08,  1.3415e-06,  6.1915e-06,  1.6564e-05, -1.0160e-05,\n",
      "          1.9558e-05,  4.0340e-06,  2.3295e-05,  2.9306e-06,  2.5848e-11,\n",
      "         -3.8694e-06,  1.5613e-08,  1.9917e-07, -1.2123e-05,  9.6476e-06],\n",
      "        [-1.2435e-05,  1.2606e-05,  2.9683e-05,  7.3597e-06,  1.7288e-06,\n",
      "         -2.2779e-05,  1.4987e-05, -6.0062e-06, -4.5655e-05,  1.3286e-05,\n",
      "          4.9503e-07, -4.9273e-05, -2.5185e-05,  2.0038e-06,  3.8273e-05,\n",
      "          1.7524e-05, -5.6457e-05, -2.8840e-05,  1.4576e-05,  1.0907e-05],\n",
      "        [-2.4365e-05,  3.0863e-05,  3.0826e-05,  3.4193e-08,  2.8114e-06,\n",
      "          1.5341e-06, -1.8368e-05,  2.0097e-05, -5.5080e-05, -1.9075e-05,\n",
      "          1.8687e-05, -3.6771e-06, -2.9383e-06,  1.5495e-06, -1.6332e-08,\n",
      "         -6.8674e-06, -8.9869e-09, -2.0840e-05,  5.3795e-08,  2.7001e-05],\n",
      "        [ 7.0418e-07, -5.6624e-06, -2.3255e-05,  1.8763e-05, -2.1588e-05,\n",
      "         -1.2279e-05, -2.2699e-05,  1.4126e-05,  4.6684e-05,  7.6772e-06,\n",
      "          2.5426e-05, -1.2545e-05, -4.1861e-05,  5.2289e-06, -2.2488e-05,\n",
      "          1.9723e-15,  5.0600e-06, -1.0212e-05,  4.0088e-06, -3.1395e-05],\n",
      "        [ 3.5574e-05, -5.5926e-05,  2.9299e-05,  6.0678e-06,  2.2201e-05,\n",
      "          8.4501e-06, -2.5331e-06,  4.1488e-05, -4.2645e-06, -3.7020e-06,\n",
      "         -5.6257e-06, -2.8924e-05, -3.0655e-10,  2.4192e-05,  2.3606e-05,\n",
      "         -8.1241e-06, -2.2200e-05,  1.2165e-05,  2.7968e-05, -3.3893e-06],\n",
      "        [ 4.2366e-05, -1.8245e-06, -9.3178e-07, -2.9607e-05, -2.3578e-05,\n",
      "         -2.7707e-06, -1.2523e-05,  7.2321e-06,  1.7084e-06, -1.2811e-05,\n",
      "          1.1935e-05, -1.8193e-06,  2.5547e-06, -9.3787e-07, -8.1626e-05,\n",
      "         -5.8643e-06, -5.4711e-06, -1.8442e-05, -1.2314e-05, -4.1480e-06],\n",
      "        [-7.3058e-06,  2.8875e-05,  2.3367e-05, -1.2858e-05,  2.5156e-09,\n",
      "          6.6616e-06,  2.6358e-05, -1.3336e-05, -1.7506e-07, -2.3959e-07,\n",
      "          3.0800e-06, -7.4896e-07, -2.4638e-05, -1.0812e-05,  3.5200e-07,\n",
      "         -1.6601e-06, -7.4543e-07,  5.2879e-06,  2.5317e-05, -2.5704e-05],\n",
      "        [ 2.8206e-05,  1.1667e-05,  7.4560e-06, -5.1800e-06, -1.3944e-06,\n",
      "          6.2981e-06, -2.4808e-05,  1.5259e-05,  2.0127e-05,  2.5201e-05,\n",
      "         -8.5629e-06,  2.2767e-09, -1.8662e-05, -2.5525e-08, -5.5181e-06,\n",
      "          2.4035e-12,  1.4230e-05, -1.3543e-05, -2.8846e-05,  5.5017e-07]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1e8625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0385, -0.0278,  0.0981,  0.1027, -0.0008,  0.0378, -0.1138, -0.0422,\n",
      "        -0.0309], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b48a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08bc018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131, 113, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09efce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77732e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing training\n",
    "X: (t, nx, ny, 4) tensor, t = 130, time step ranges from 0 - 130\n",
    "Y: (t, nx, ny) tensor, t = 130, time step ranges from    0 - 149 \n",
    "at each time step t, using X to predict Y at time t + 19, (based on the forward function in the sample.)\n",
    "hence we need Y at t+ 1 to Y at t + 19 to train the model and validate the predictions \n",
    "\"\"\"\n",
    "# testing \n",
    "id, X, Y = getTrainData(1)\n",
    "\n",
    "# model takes in 'data' as the training / testing input \n",
    "# \n",
    "data = X\n",
    "target = Y\n",
    "\n",
    "# the mdoel takes input features 20, output feature 9\n",
    "# input features include 9 fire status, 9 theta status, 1 wind speed, 1 slope \n",
    "# output features include 9 updated fire status\n",
    "input_size = 20\n",
    "output_size = 9\n",
    "\n",
    "# Create LSSVM model\n",
    "model = FireSpreadModel_LSSVM(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_lssvm(model, X, Y, epochs = 3, lr = 0.005, c = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
