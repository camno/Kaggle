{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687f076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#### INSTRUCTIONS FOR I/O (PLEASE READ) #######\n",
    "# Input data files are available in the read-only \"../input/\" (relative) or '/kaggle/input'(absolute) directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "input_path = '2024-flame-ai-challenge/dataset/'\n",
    "output_path = 'working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e390428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>u</th>\n",
       "      <th>alpha</th>\n",
       "      <th>Nt</th>\n",
       "      <th>Nx</th>\n",
       "      <th>Ny</th>\n",
       "      <th>theta_filename</th>\n",
       "      <th>ustar_filename</th>\n",
       "      <th>xi_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219547</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>theta_K_id219547.dat</td>\n",
       "      <td>ustar_ms-1_id219547.dat</td>\n",
       "      <td>xi_id219547.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167403</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>theta_K_id167403.dat</td>\n",
       "      <td>ustar_ms-1_id167403.dat</td>\n",
       "      <td>xi_id167403.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225258</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>theta_K_id225258.dat</td>\n",
       "      <td>ustar_ms-1_id225258.dat</td>\n",
       "      <td>xi_id225258.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>890407</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>theta_K_id890407.dat</td>\n",
       "      <td>ustar_ms-1_id890407.dat</td>\n",
       "      <td>xi_id890407.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352206</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>theta_K_id352206.dat</td>\n",
       "      <td>ustar_ms-1_id352206.dat</td>\n",
       "      <td>xi_id352206.dat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  u  alpha  Nt   Nx  Ny        theta_filename  \\\n",
       "0  219547  5    2.5   5  113  32  theta_K_id219547.dat   \n",
       "1  167403  5    2.5   5  113  32  theta_K_id167403.dat   \n",
       "2  225258  5    2.5   5  113  32  theta_K_id225258.dat   \n",
       "3  890407  5   25.0   5  113  32  theta_K_id890407.dat   \n",
       "4  352206  5   25.0   5  113  32  theta_K_id352206.dat   \n",
       "\n",
       "            ustar_filename      xi_filename  \n",
       "0  ustar_ms-1_id219547.dat  xi_id219547.dat  \n",
       "1  ustar_ms-1_id167403.dat  xi_id167403.dat  \n",
       "2  ustar_ms-1_id225258.dat  xi_id225258.dat  \n",
       "3  ustar_ms-1_id890407.dat  xi_id890407.dat  \n",
       "4  ustar_ms-1_id352206.dat  xi_id352206.dat  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(input_path,'test.csv'))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3a1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets test set input\n",
    "def getTestX(idx):\n",
    "    csv_file = test_df.reset_index().to_dict(orient='list')\n",
    "    dir_path = os.path.join(input_path, \"test\")\n",
    "    id = csv_file['id'][idx]\n",
    "    nt, Nx, Ny = csv_file['Nt'][idx], csv_file['Nx'][idx], csv_file['Ny'][idx]\n",
    "    theta = np.fromfile(os.path.join(dir_path, csv_file['theta_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    xi_f = np.fromfile(os.path.join(dir_path, csv_file['xi_filename'][idx]), dtype=\"<f4\").reshape(nt, Nx, Ny)\n",
    "    uin  = np.array(csv_file['u'][idx])\n",
    "    alpha = np.array(csv_file['alpha'][idx])\n",
    "    uin = np.full_like(theta,uin)\n",
    "    alpha = np.full_like(theta,alpha)\n",
    "\n",
    "    X = np.stack([theta,xi_f,uin,alpha],axis=-1) # (t, Nx, Ny, c) \n",
    "    X = torch.tensor(X)\n",
    "    return id,X\n",
    "\n",
    "#predicts with input\n",
    "def predict(idx,model):\n",
    "    id,X = getTestX(idx)\n",
    "    X = X.unsqueeze(0)\n",
    "    y_pred = model(X)\n",
    "    return id,y_pred\n",
    "\n",
    "#generates submission with model predictions already in SI units\n",
    "def generate_submission(model):\n",
    "    y_preds = {}\n",
    "    ids = []\n",
    "    for idx in range(len(test_df)):\n",
    "        id, y_pred = predict(idx, model) \n",
    "        #WARNING tmp should be in SI units\n",
    "        y_preds[id]= np.array(y_pred).flatten(order='C').astype(np.float32)\n",
    "        ids.append(id)\n",
    "    df = pd.DataFrame.from_dict(y_preds,orient='index')\n",
    "    df['id'] = ids\n",
    "\n",
    "    # move id to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    #reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca278c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a torch model based on linear interpolation of fire spread\n",
    "# REPLACE THIS WITH YOUR MODEL LOADER TO MAKE YOUR PREDICTIONS\n",
    "class FireSpreadModel(nn.Module):\n",
    "    def __init__(self, n_predictions=5):\n",
    "        super(FireSpreadModel, self).__init__()\n",
    "        self.n_predictions = n_predictions\n",
    "        # Constants\n",
    "        self.R_2_0 = 0.89492756  # m/s\n",
    "        self.R_6_0 = 1.7765957\n",
    "        self.R_2_10 = 2.009707\n",
    "        \n",
    "        # Calculate slopes for u10 and slope effects\n",
    "        self.k_u = (self.R_6_0 - self.R_2_0) / (6 - 2)\n",
    "        self.k_slope = (self.R_2_10 - self.R_2_0) / (10 - 0)\n",
    "    \n",
    "    def find_initial_location(self, indicator):\n",
    "        initial_index = -1\n",
    "        for i in range(indicator.shape[1]): \n",
    "            if indicator[-1,i,0] > 0:\n",
    "                initial_index = i\n",
    "                break\n",
    "        return initial_index\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        This model takes in:\n",
    "        data:(time_steps, nx, ny, 4) tensor containing the input data\n",
    "        Outputs:\n",
    "        - xi_f_predictions: (n_predictions, nx, ny)\n",
    "        \"\"\"\n",
    "        indicator = data[:, :, :, :, 1].squeeze()\n",
    "        u10 = data[:, :, :, :, 2].squeeze()\n",
    "        u10 = u10.mean()                         # we are only interested in the u as single value\n",
    "        slope = data[:, :, :, :, 3].squeeze()    # we are only interested in the slope as single value\n",
    "        slope = slope.mean()\n",
    "        # Calculate displacement per second\n",
    "        displ_per_second = self.R_2_0 + self.k_u * (u10 - 2) + self.k_slope * (slope - 0)\n",
    "        \n",
    "        initial_index = self.find_initial_location(indicator)\n",
    "\n",
    "        xi_f = initial_index*8 + displ_per_second\n",
    "        indicator_predictions = torch.zeros((self.n_predictions, indicator.shape[1], indicator.shape[2]))\n",
    "\n",
    "        # Predict the next locations\n",
    "        for i in range(1, self.n_predictions):\n",
    "            indicator_predictions[i,int(xi_f/8),:] = 1\n",
    "            xi_f = xi_f + displ_per_second\n",
    "            \n",
    "\n",
    "        return indicator_predictions # (20, nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2339a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Submission file ... completed\n"
     ]
    }
   ],
   "source": [
    "model = FireSpreadModel(n_predictions=20)\n",
    "# predict(0, model)\n",
    "df = generate_submission(model)\n",
    "df.to_csv(os.path.join(output_path, 'submission.csv'),index=False)\n",
    "print('Generating Submission file ... completed' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b0809c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
